{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    cn = []\n",
    "    en = []\n",
    "    with open(file, 'r', encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            en.append(['BOS'] + nltk.word_tokenize(line[0].lower()) + ['EOS'])\n",
    "            cn.append(['BOS'] + [w for w in line[1]] + ['EOS'])\n",
    "    return en, cn \n",
    "\n",
    "train_file = 'nmt/train.txt'\n",
    "dev_file = 'nmt/dev.txt'\n",
    "test_file = 'nmt/test.txt'\n",
    "train_en, train_cn = load_data(train_file)\n",
    "dev_en, dev_cn = load_data(dev_file)\n",
    "test_en, test_cn = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['BOS', 'anyone', 'can', 'do', 'that', '.', 'EOS'], ['BOS', 'how', 'about', 'another', 'piece', 'of', 'cake', '?', 'EOS'], ['BOS', 'she', 'married', 'him', '.', 'EOS'], ['BOS', 'i', 'do', \"n't\", 'like', 'learning', 'irregular', 'verbs', '.', 'EOS'], ['BOS', 'it', \"'s\", 'a', 'whole', 'new', 'ball', 'game', 'for', 'me', '.', 'EOS']]\n",
      "------------------------------------------------------------------\n",
      "[['BOS', '任', '何', '人', '都', '可', '以', '做', '到', '。', 'EOS'], ['BOS', '要', '不', '要', '再', '來', '一', '塊', '蛋', '糕', '？', 'EOS'], ['BOS', '她', '嫁', '给', '了', '他', '。', 'EOS'], ['BOS', '我', '不', '喜', '欢', '学', '习', '不', '规', '则', '动', '词', '。', 'EOS'], ['BOS', '這', '對', '我', '來', '說', '是', '個', '全', '新', '的', '球', '類', '遊', '戲', '。', 'EOS']]\n"
     ]
    }
   ],
   "source": [
    "print(train_en[:5]) \n",
    "print('------------------------------------------------------------------')\n",
    "print(train_cn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5493\n",
      "3195\n"
     ]
    }
   ],
   "source": [
    "unk_id = 0\n",
    "pad_id = 1\n",
    "\n",
    "def build_dict(sentences, max_words = 50000):\n",
    "    word_count = Counter()\n",
    "    for sentence in sentences:\n",
    "        for w in sentence:\n",
    "            word_count[w] += 1\n",
    "    ls = word_count.most_common(max_words)\n",
    "    total_words = len(ls) + 2\n",
    "    print(total_words)\n",
    "    \n",
    "    word_dict = {w[0]: index+2 for index, w in enumerate(ls)}  \n",
    "    word_dict['UNK'] = unk_id\n",
    "    word_dict['PAD'] = pad_id\n",
    "    \n",
    "    return word_dict, total_words\n",
    "\n",
    "en_dict_id, en_total_words = build_dict(train_en)\n",
    "cn_dict_id, cn_total_words = build_dict(train_cn)\n",
    "\n",
    "id_dict_en = {v: k for k, v in en_dict_id.items()}\n",
    "id_dict_cn = {v: k for k, v in cn_dict_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5493\n",
      "[('BOS', 2), ('EOS', 3), ('.', 4), ('i', 5), ('the', 6), ('to', 7), ('you', 8), ('a', 9), ('is', 10), ('?', 11)]\n",
      "\n",
      "[('opposition', 5485), ('springs', 5486), ('schoolroom', 5487), ('absence', 5488), ('fonder', 5489), ('field', 5490), ('educational', 5491), ('foster', 5492), ('UNK', 0), ('PAD', 1)]\n",
      "------------------------------------------------------------\n",
      "3195\n",
      "[('BOS', 2), ('EOS', 3), ('。', 4), ('我', 5), ('的', 6), ('了', 7), ('你', 8), ('他', 9), ('是', 10), ('一', 11)]\n",
      "\n",
      "[('鷹', 3187), ('鸚', 3188), ('鵡', 3189), ('寵', 3190), ('鳴', 3191), ('缓', 3192), ('黨', 3193), ('釘', 3194), ('UNK', 0), ('PAD', 1)]\n",
      "------------------------------------------------------------\n",
      "[(2, 'BOS'), (3, 'EOS'), (4, '.'), (5, 'i'), (6, 'the'), (7, 'to'), (8, 'you'), (9, 'a'), (10, 'is'), (11, '?')]\n",
      "\n",
      "[(5485, 'opposition'), (5486, 'springs'), (5487, 'schoolroom'), (5488, 'absence'), (5489, 'fonder'), (5490, 'field'), (5491, 'educational'), (5492, 'foster'), (0, 'UNK'), (1, 'PAD')]\n",
      "------------------------------------------------------------\n",
      "[(2, 'BOS'), (3, 'EOS'), (4, '。'), (5, '我'), (6, '的'), (7, '了'), (8, '你'), (9, '他'), (10, '是'), (11, '一')]\n",
      "\n",
      "[(3187, '鷹'), (3188, '鸚'), (3189, '鵡'), (3190, '寵'), (3191, '鳴'), (3192, '缓'), (3193, '黨'), (3194, '釘'), (0, 'UNK'), (1, 'PAD')]\n"
     ]
    }
   ],
   "source": [
    "print(en_total_words)\n",
    "print(list(en_dict_id.items())[:10]) # 取出前10个\n",
    "print()\n",
    "print(list(en_dict_id.items())[-10:]) # 取出后10个，可以看到\"unk\"和\"pad\"在最后\n",
    "print(\"---\"*20)\n",
    "print(cn_total_words)\n",
    "print(list(cn_dict_id.items())[:10]) # 查看中文\n",
    "print()\n",
    "print(list(cn_dict_id.items())[-10:]) \n",
    "print(\"---\"*20)\n",
    "print(list(id_dict_en.items())[:10]) # 键值对调换\n",
    "print()\n",
    "print(list(id_dict_en.items())[-10:]) \n",
    "print(\"---\"*20)\n",
    "print(list(id_dict_cn.items())[:10]) # 键值对调换\n",
    "print()\n",
    "print(list(id_dict_cn.items())[-10:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将单词全部转变成数字\n",
    "def encode(en_sentences, cn_sentences, en_dict_id, cn_dict_id, sort_by_len = True):\n",
    "    length = len(en_sentences)\n",
    "    out_en_sentences = [[en_dict_id.get(w, 0) for w in sent] for sent in en_sentences]\n",
    "    out_cn_sentences = [[cn_dict_id.get(w, 0) for w in sent] for sent in cn_sentences]\n",
    "    \n",
    "    def len_sort(seq):  # 将句子按长度进行排列，给出从小到大的句子的索引号\n",
    "        return sorted(range(len(seq)), key = lambda x: len(seq[x]))\n",
    "    \n",
    "    if sort_by_len:\n",
    "        sorted_index = len_sort(out_en_sentences)  # 将句子按长度进行排列，给出从小到大的句子的索引号\n",
    "        out_en_sentences = [out_en_sentences[i] for i in sorted_index]  #通过索引将句子取出\n",
    "        out_cn_sentences = [out_cn_sentences[i] for i in sorted_index]\n",
    "    \n",
    "    return out_en_sentences, out_cn_sentences\n",
    "\n",
    "train_en, train_cn = encode(train_en, train_cn, en_dict_id, cn_dict_id)\n",
    "dev_en, dev_cn = encode(dev_en, dev_cn, en_dict_id, cn_dict_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 475, 4, 3], [2, 1318, 126, 3], [2, 1707, 126, 3], [2, 254, 126, 3], [2, 1318, 126, 3], [2, 130, 11, 3], [2, 2045, 126, 3], [2, 693, 126, 3], [2, 2266, 126, 3], [2, 1707, 126, 3]]\n",
      "=====================================\n",
      "[[2, 8, 87, 441, 6, 4, 3], [2, 119, 1368, 221, 3], [2, 982, 2028, 8, 4, 3], [2, 239, 239, 221, 3], [2, 151, 190, 221, 3], [2, 8, 546, 162, 14, 3], [2, 141, 488, 6, 221, 3], [2, 18, 489, 221, 3], [2, 189, 158, 221, 3], [2, 2110, 60, 221, 3]]\n",
      "====================================\n",
      "['BOS', 'get', 'out', '!', 'EOS']\n",
      "['BOS', '滾', '出', '去', '！', 'EOS']\n",
      "BOS get out ! EOS\n",
      "BOS 滾 出 去 ！ EOS\n"
     ]
    }
   ],
   "source": [
    "print(train_en[:10])\n",
    "print('=====================================')\n",
    "print(train_cn[:10])\n",
    "print('====================================')\n",
    "print([id_dict_en[i] for i in train_en[100]])\n",
    "print([id_dict_cn[i] for i in train_cn[100]])\n",
    "print(' '.join([id_dict_en[i] for i in train_en[100]]))\n",
    "print(' '.join([id_dict_cn[i] for i in train_cn[100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n是数据集长度，minibatch_size为一个batc中的个数\n",
    "def get_minibatches(n, minibatch_size, shuffle = True):\n",
    "    id_list = np.arange(0, n, minibatch_size)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(id_list)\n",
    "    minibatch = []\n",
    "    for i in id_list:\n",
    "        minibatch.append(np.arange(i, min(i+minibatch_size, n)))\n",
    "    return minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]),\n",
       " array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       " array([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]),\n",
       " array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]),\n",
       " array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " array([45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_minibatches(100, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(seqs):\n",
    "    lengths = [len(seq) for seq in seqs]\n",
    "    n_samples = len(seqs)\n",
    "    max_len = np.max(lengths)\n",
    "    x = np.zeros((n_samples, max_len)).astype('int32') #[0,0,0,0,0,0,0,0,0,0]\n",
    "    x_lengths = np.array(lengths).astype('int32')\n",
    "    for i, seq in enumerate(seqs):\n",
    "        x[i, :lengths[i]] = seq  #将全是0的进行填充为之前的seq, [2,3,7,1,0,0,0,0,0]\n",
    "    return x, x_lengths #x：填充好的seq，x_lengths：seqs里每个seq的长度\n",
    "        \n",
    "        \n",
    "        \n",
    "def gen_examples(en_sentences, cn_sentences, batch_size):\n",
    "    minibatches = get_minibatches(len(en_sentences), batch_size)\n",
    "    all_ex = []\n",
    "    for minibatch in minibatches:\n",
    "        batch_en_sentences = [en_sentences[t] for t in minibatch]\n",
    "        batch_cn_sentences = [cn_sentences[t] for t in minibatch]\n",
    "        mb_zn, mb_zn_len = pad_data(batch_en_sentences)\n",
    "        mb_cn, mb_cn_len = pad_data(batch_cn_sentences)\n",
    "        \n",
    "        all_ex.append((mb_zn, mb_zn_len, mb_cn, mb_cn_len))\n",
    "    return all_ex        \n",
    "\n",
    "batch_size = 64\n",
    "train_data = gen_examples(train_en, train_cn, batch_size)\n",
    "random.shuffle(train_data)\n",
    "dev_data = gen_examples(dev_en, dev_cn, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 9)\n",
      "(64,)\n",
      "(64, 16)\n",
      "(64,)\n",
      "(array([[   2,    5,   56,   73,    8,  150,  311,    4,    3],\n",
      "       [   2,   32,  261,   10,  213,  368, 1747,    4,    3],\n",
      "       [   2,   12,   93,   35,  365,    9,  925,    4,    3],\n",
      "       [   2,   77,   10,  698,   15,  125, 1048,    4,    3],\n",
      "       [   2,  643,   10,   66,   26,   32,  477,    4,    3],\n",
      "       [   2,   51, 1400,  515,   62,   21, 4376,    4,    3],\n",
      "       [   2,   31,    5,   42,  608,   10,  357,    4,    3],\n",
      "       [   2,  505,   10, 1900,   33,   25,  492,    4,    3],\n",
      "       [   2,   18,  542,   23, 2553,   21,  261,    4,    3],\n",
      "       [   2,   29,   84,   33,    6,  200,   44,    4,    3],\n",
      "       [   2,   29,  109,  124,  812,   18,   57,    4,    3],\n",
      "       [   2,  709,    8,   67,  111,  154,   57,    4,    3],\n",
      "       [   2,   19, 1378,    7,   22,    9, 1140,    4,    3],\n",
      "       [   2,    5,   79,  279,  274,   21,  314,    4,    3],\n",
      "       [   2,   80,   14,    8,  113,   16,   65,   11,    3],\n",
      "       [   2,   16,   27,    9,   50,  672, 1452,    4,    3],\n",
      "       [   2,    5,   76,  298,   17,   21,  107,    4,    3],\n",
      "       [   2,   59,   20,   64,  430,  124,  102,    4,    3],\n",
      "       [   2,   52,   69,  338,  885,   17,  263,   11,    3],\n",
      "       [   2,   12,  187,   99,    7,  181,  556,    4,    3],\n",
      "       [   2,   12,   70,   13,   22,  116,  212,    4,    3],\n",
      "       [   2,    6,  480,   27,  651,   65,   23,    4,    3],\n",
      "       [   2,   31,   12,  438,   10, 1949, 2290,    4,    3],\n",
      "       [   2,   12,   85,   13,  273,   21,  655,    4,    3],\n",
      "       [   2,   58,   91,   23,  293,    6,  471,    4,    3],\n",
      "       [   2,   31,   14,    8,   54,    7,   39,   11,    3],\n",
      "       [   2,   35,  133,   10,  503,    6,  448,    4,    3],\n",
      "       [   2,    5,  429,   46, 1385,    6,  386,    4,    3],\n",
      "       [   2,   52,   14,    8,  141,    9,  534,   11,    3],\n",
      "       [   2,   18,   67,   22,  907,   17,   60,    4,    3],\n",
      "       [   2,   18,  257,    7,   45,    7,  719,    4,    3],\n",
      "       [   2,    5,  594,  844,  459,   33,   16,    4,    3],\n",
      "       [   2,   16,   20,  648,   17,   32,  468,    4,    3],\n",
      "       [   2,  648,   17,   21,  212,  268,  263,    4,    3],\n",
      "       [   2,   19,   93,    6, 1236,   26,   23,    4,    3],\n",
      "       [   2,    6,  881,  123, 1463,    6, 2415,    4,    3],\n",
      "       [   2,   18,   10,   74,   17,   32, 4395,    4,    3],\n",
      "       [   2,   31,   10,   32,  900,   17, 1190,   11,    3],\n",
      "       [   2,   12,   63,    9, 1218,  161,  399,    4,    3],\n",
      "       [   2,   16, 1507,   26,  213, 4399,  305,    4,    3],\n",
      "       [   2,   29,   22,  169,  551,   17, 1574,    4,    3],\n",
      "       [   2,   35,  419,   10,  120,   50, 2648,    4,    3],\n",
      "       [   2,   29,   79,  279, 4402,   61,  153,    4,    3],\n",
      "       [   2,    5,  211,   12,   86,   59,   95,    4,    3],\n",
      "       [   2,   19,  144,   99,    9, 2063,  285,    4,    3],\n",
      "       [   2,    6, 2946, 2795,  201,    6,  881,    4,    3],\n",
      "       [   2,    5,   42,  272,  175,   35,  947,    4,    3],\n",
      "       [   2,   12, 4406,    7,  154,   57,  476,    4,    3],\n",
      "       [   2,    8,   90,   32,  478, 1515, 1531,    4,    3],\n",
      "       [   2,   61,   17,   21, 4407,   22, 1014,    4,    3],\n",
      "       [   2,   21,  481,  191,   10,    9,  223,    4,    3],\n",
      "       [   2,   12, 1621,   16,  656,    6,  210,    4,    3],\n",
      "       [   2,   91,   20,   89,    9,  763,   95,    4,    3],\n",
      "       [   2,  648,   17,    6,  127,   10,  513,    4,    3],\n",
      "       [   2,   21,  649,  144,   23,   64, 1361,    4,    3],\n",
      "       [   2,   43,    5, 1998,   26,   28,  388,   11,    3],\n",
      "       [   2,   14,    8,  197,  284,   62,   46,   11,    3],\n",
      "       [   2,  465,   23,    9, 1509,   17,  214,    4,    3],\n",
      "       [   2,   18,   85,   13,  110,  121, 1095,    4,    3],\n",
      "       [   2,   87,   41,    8,   45,   26,  667,   11,    3],\n",
      "       [   2,   12,  227,  207,  122,  104, 1030,    4,    3],\n",
      "       [   2,   51,   30,  712,   17,  188,  439,    4,    3],\n",
      "       [   2,   18, 1441,   23,   26,    6, 1001,    4,    3],\n",
      "       [   2,   29,  136,   37,  763,  118,  880,    4,    3]]), array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]), array([[  2,   5,  55, ...,   0,   0,   0],\n",
      "       [  2,   8,   6, ...,   0,   0,   0],\n",
      "       [  2,   9,  43, ...,   3,   0,   0],\n",
      "       ...,\n",
      "       [  2,   9,  24, ...,   0,   0,   0],\n",
      "       [  2, 159,  19, ...,   0,   0,   0],\n",
      "       [  2,   5,  24, ...,   3,   0,   0]]), array([11, 12, 14, 12, 12, 14,  9, 12, 14, 14, 11, 10, 12, 13,  9, 14, 11,\n",
      "       10, 12, 13, 10,  7, 13, 12, 13,  9, 11, 10,  9, 12, 11, 14, 11, 12,\n",
      "       12, 12, 12, 10, 12, 10, 12, 12, 16, 12, 15, 10, 11,  9, 13, 13, 11,\n",
      "       11, 15, 11, 15, 12, 13,  8, 13, 10, 12, 13, 13, 14]))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][2].shape)\n",
    "print(train_data[0][3].shape)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, dropout=0.2):\n",
    "        super(PlainEncoder, self).__init__()\n",
    "        self.embed = nn.embedding(vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        '''x:batch的句子， lengths为句子的长度'''\n",
    "        # 因为需要把最后一个hidden state取出来，需要知道长度，因为句子长度不一样\n",
    "        sorted_len, sorted_id = lengths.sort(0, descending = True)\n",
    "        x_sorted = x[sorted_id.long()]\n",
    "        embedded = self.dropout(self.embed(x_sorted))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(), batch_first = True)\n",
    "        packed_out, hid = self.rnn(packed_embedded)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sentence(packed_out, batch_first=True)\n",
    "        _, original_id = sorted_id.sort(0, descending=False)\n",
    "        out = out[original_id.long()].contiguous()\n",
    "        hid = hid[:, original_id.long()].contigous()\n",
    "        \n",
    "        return out, hid[[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, dropout=0.2):\n",
    "        super(PlainDecoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, bathc_first=True)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, y, y_lengths, hid):\n",
    "        sorted_len, sorted_id = y_lengths.sort(0, descending=True)\n",
    "        y_sorted = y[sorted_id.long()]\n",
    "        hid = hid[:, sorted_id.long()]\n",
    "        y_sorted = self.dropout(self.embed(y_sorted))\n",
    "        \n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first = True)\n",
    "        out, hid = self.rnn(packed_seq, hid)\n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_size=True)\n",
    "        _, original_id = sorted_id.sort(0, descending=False)\n",
    "        output_seq = unpacked[original_id.long()].contiguous()\n",
    "        hid = hid[:, original_id.long()].contiguous()\n",
    "        output = F.log_softmax(self.out(output_seq), -1)\n",
    "        return output, hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondac1ed852f726f46e99aa9eda212d43d36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
